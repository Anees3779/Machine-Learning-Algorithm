{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4274e551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94efcf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd919bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62307c67",
   "metadata": {},
   "source": [
    "## Exploratory  Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6991462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for getting the shape (No of rows & columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b2d664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Details\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d90d3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting brief summary of data \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b02396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Null Values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8cee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary of dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66179dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdbac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = df.corr()\n",
    "sns.heatmap(cor, cmap=\"crest\", annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd60e444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the number of zero-values in in each column\n",
    "print('rows having null Pregnancies value : {0}'.format(len(df.loc[df['Pregnancies'] == 0])))\n",
    "print('rows having null Glucose value : {0}'.format(len(df.loc[df['Glucose'] == 0])))\n",
    "print('rows having null BloodPressure value : {0}'.format(len(df.loc[df['BloodPressure'] == 0])))\n",
    "print('rows having null SkinThickness value : {0}'.format(len(df.loc[df['SkinThickness'] == 0])))\n",
    "print('rows having null Insulin value : {0}'.format(len(df.loc[df['Insulin'] == 0])))\n",
    "print('rows having null BMI value : {0}'.format(len(df.loc[df['BMI'] == 0])))\n",
    "print('rows having null DiabetesPedigreeFunction value : {0}'.format(len(df.loc[df['DiabetesPedigreeFunction'] == 0])))\n",
    "print('rows having null Age value : {0}'.format(len(df.loc[df['Age'] == 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1d5981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the mean value of every column\n",
    "means = df.iloc[:, 1:6].mean()\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9c56f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzeros = list(df.columns[1:6])\n",
    "for column in nonzeros:\n",
    "    df[column] = df[column].replace(0, means[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0419c8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview of Changed Dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6717b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_counts = df['Outcome'].value_counts()\n",
    "print(outcome_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9565694d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_improve =df[['Glucose','BMI','Age','Insulin','Outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815d3ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# improved dataset after datacleaning\n",
    "df_improve.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7485e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_improve.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af69ce89",
   "metadata": {},
   "source": [
    "## Data Visualisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f16eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap\n",
    "cor = df_improve.corr()\n",
    "sns.heatmap(cor, cmap=\"crest\", annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79aa5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot\n",
    "sns.pairplot(df_improve,hue='Outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5af082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "features = df_improve.columns.tolist()\n",
    "features.remove('Outcome')\n",
    "# Create histograms for each feature with 'Outcome' as the hue\n",
    "for feature in features:\n",
    "    sns.histplot(data=df_improve, x=feature, hue='Outcome', kde=True)\n",
    "    plt.title(f'Histogram of {feature}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb3480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pie chart\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(outcome_counts, labels=['Fit', 'Diabetic'], autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Outcome Count by Fit and Diabetic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0658a899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the count of each class in the 'Outcome' column\n",
    "sns.countplot(x=df_improve['Outcome'], data=df_improve)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceee658e",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe617dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_improve.loc[:, ['Glucose', 'Insulin','BMI','Age']].to_numpy()\n",
    "y = df_improve.loc[:, 'Outcome'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5abb5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a767f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b825481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardising the Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f24f8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b570e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_data = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275e0743",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(standardized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863b8d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = standardized_data\n",
    "target = df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473ac84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ec1b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ce2e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725d8552",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba45388",
   "metadata": {},
   "source": [
    "## Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b866235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None,*,value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "        \n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf84a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, min_samples_split=2, max_depth=100, n_features=None):\n",
    "        self.min_samples_split=min_samples_split\n",
    "        self.max_depth=max_depth\n",
    "        self.n_features=n_features\n",
    "        self.root=None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_features = X.shape[1] if not self.n_features else min(X.shape[1],self.n_features)\n",
    "        self.root = self._grow_tree(X, y)\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        n_samples, n_feats = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    "\n",
    "        # check the stopping criteria\n",
    "        if (depth>=self.max_depth or n_labels==1 or n_samples<self.min_samples_split):\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return Node(value=leaf_value)\n",
    "\n",
    "        feat_idxs = np.random.choice(n_feats, self.n_features, replace=False)\n",
    "\n",
    "        # find the best split\n",
    "        best_feature, best_thresh = self._best_split(X, y, feat_idxs)\n",
    "\n",
    "        # create child nodes\n",
    "        left_idxs, right_idxs = self._split(X[:, best_feature], best_thresh)\n",
    "        left = self._grow_tree(X[left_idxs, :], y[left_idxs], depth+1)\n",
    "        right = self._grow_tree(X[right_idxs, :], y[right_idxs], depth+1)\n",
    "        return Node(best_feature, best_thresh, left, right)\n",
    "    \n",
    "    def _best_split(self, X, y, feat_idxs):\n",
    "        best_gain = -1\n",
    "        split_idx, split_threshold = None, None\n",
    "\n",
    "        for feat_idx in feat_idxs:\n",
    "            X_column = X[:, feat_idx]\n",
    "            thresholds = np.unique(X_column)\n",
    "\n",
    "            for thr in thresholds:\n",
    "                # calculate the information gain\n",
    "                gain = self._information_gain(y, X_column, thr)\n",
    "\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    split_idx = feat_idx\n",
    "                    split_threshold = thr\n",
    "\n",
    "        return split_idx, split_threshold\n",
    "    \n",
    "    def _information_gain(self, y, X_column, threshold):\n",
    "        # parent entropy\n",
    "        parent_entropy = self._entropy(y)\n",
    "\n",
    "        # create children\n",
    "        left_idxs, right_idxs = self._split(X_column, threshold)\n",
    "\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0\n",
    "        \n",
    "        # calculate the weighted avg. entropy of children\n",
    "        n = len(y)\n",
    "        n_l, n_r = len(left_idxs), len(right_idxs)\n",
    "        e_l, e_r = self._entropy(y[left_idxs]), self._entropy(y[right_idxs])\n",
    "        child_entropy = (n_l/n) * e_l + (n_r/n) * e_r\n",
    "\n",
    "        # calculate the IG\n",
    "        information_gain = parent_entropy - child_entropy\n",
    "        return information_gain\n",
    "\n",
    "    def _split(self, X_column, split_thresh):\n",
    "        left_idxs = np.argwhere(X_column <= split_thresh).flatten()\n",
    "        right_idxs = np.argwhere(X_column > split_thresh).flatten()\n",
    "        return left_idxs, right_idxs\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        hist = np.bincount(y)\n",
    "        ps = hist / len(y)\n",
    "        return -np.sum([p * np.log(p) for p in ps if p>0])\n",
    "    \n",
    "    def _most_common_label(self, y):\n",
    "        counter = Counter(y)\n",
    "        value = counter.most_common(1)[0][0]\n",
    "        return value\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._traverse_tree(x, self.root) for x in X])\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        if node.is_leaf_node():\n",
    "            return node.value\n",
    "\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        return self._traverse_tree(x, node.right)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0386c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_DT = DecisionTree(max_depth=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e3df62",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_DT.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c8440f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_DT = clf_DT.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f07e383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_test, y_pred_DT):\n",
    "    return np.sum(y_test == y_pred_DT) / len(y_test)\n",
    "\n",
    "acc = accuracy(y_test, y_pred_DT)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775e65e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4148a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_performance(y_test, y_pred_DT):\n",
    "    test_accuracy = accuracy_score(y_test, y_pred_DT)\n",
    "    test_precision = precision_score(y_test, y_pred_DT)\n",
    "    test_recall = recall_score(y_test, y_pred_DT)\n",
    "    test_f1 = f1_score(y_test, y_pred_DT)\n",
    "\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    print(\"Test Precision:\", test_precision)\n",
    "    print(\"Test Recall:\", test_recall)\n",
    "    print(\"Test F1 Score:\", test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdec9ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model_performance(y_test, y_pred_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa12b555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb291a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bb0a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac09032",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test, y_pred_DT)\n",
    "\n",
    "# You have a typo in the following line. Instead of \"pd.df(cfn_matrix)\", you should use \"pd.DataFrame(cfn_matrix)\".\n",
    "sns.heatmap(pd.DataFrame(cm), annot=True, cmap=\"YlGnBu\", fmt='g')\n",
    "plt.title('Confusion Matrix', y=1.1)\n",
    "plt.ylabel('Actual Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2572ee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test,y_pred_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82687a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9f7b44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
